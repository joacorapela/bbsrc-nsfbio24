
\documentclass[12pt]{article}

\usepackage{graphicx}
\usepackage{verbatim}
\usepackage[colorlinks=true]{hyperref}
\usepackage{natbib}

\title{Enabling naturalistic, long-duration and continual animal experimentation}

\begin{document}

\maketitle

\tableofcontents
\pagebreak

\section{Vision}

For over four years, at the Sainsbury Wellcome Centre and Gatsby Computational
Neuroscience Unit, we have been developing the AEON platform, a set of hardware
and software tools that support a new type of experimentation, where animals
are allowed to express ethologically-relevant behaviors, in naturalistic
environments, and in long-duration experiments, while their behavior and
neural activity is monitored continuously for weeks to months.
%
We have used this platform to characterize foraging behavior in both solitary
and groups of mice~\citep{aeonRepo} (Figure~\ref{fig:aeonPlatform}).

Our US partner, the Allen Institute for Neural Dynamics, is using the AEON
platform in continuous learning experiments, where mice freely explore odors
continuously for days to weeks~\citep{carlsPapers}.

This is an unprecedented type of experimentation that \ldots

Several groups around the world are performing this new type of
experimentation~\cite{}.

We have built the AEON platform, and have used it to collect weeks- to
months-long NaLoDuCo experimental data. We next propose to develop advanced
machine learning methods and intelligent visualisations to extract meaning from
this data (Aim 1).

A central aim of both the SWC/GCNU and AIND is to contribute to open science.
We thus propose to create software infrastructure to openly disseminate
NaLoDuCo recordings, visualisation and data analysis methods (Aim 2).

Over more than four years we have developed the AEON platform following high
software engineering practices. It is an open source platform that anybody can
use and modify~\citep{aeonResources}. We want it to become the standard platform for the collection
of NaLoDuCo experimental data.
%
We are currently using AEON on two new NaLoDuCo experiments: (1) odor learning
experiments, lasting for days to weeks, lead by Dr.~Carl Schoonover at the
AIND, and (2) foraging experiments in very large arenas (eight meters in
diameter), lead by Prof.~Tiago Branco at the SWC.
%
We will extend and validate the functionality of the AEON platform by applying
it to these and new NaLoDuCo experiments.
%
A key functionality that we propose to add as part of this project is real-time
machine learning, to allow to control AEON experiments with live inferences
(Aim 3).

\begin{figure}
    \begin{center}
        \includegraphics[width=5in]{figures/aims.png}
    \end{center}
    \caption{Proposal aims}
    \label{fig:aims}
\end{figure}

\subsection*{Aim 1: create infrastructure for open dissemination of NaLoDuCo
experimental recordings}

The dissemination of NaLoDuCo recordings is not
trivial, as datasets generated by this new type of experimentation are
enormous. For instance, the size of a dataset generated from a one week
recording of behavioral and neural activity from a foraging mouse in SWC
experiments exceeds 200 terabytes. It will take users several days to download
these datasets over standard Internet connections.

Instead of bringing data to users, we will bring users to data, by storing
datasets in the cloud (or in institutional clusters), and providing
\textbf{cloud software to allow users to visually explore and statistically
analyse behavioural and neural NaLoDuCo datasets where they live}
(Figure~\ref{fig:aims}, left box).

Our statistical analysis of neural time series will require knowledge of the
spiking activity of single units; i.e., spike sorting. In long-duration
experiments with freely moving animals spike sorting is a challenging problem,
because movements of recording probes change the shape of spike waveforms over
time and complicate the assignment of spikes to units based on their waveforms.
We will address this problem by developing \textbf{spike sorting methods for
long-duration and continual, long-duration and high-channel-count recordings}
(Figure~\ref{fig:aims}, left box).

\subsection*{Aim 2: create real-time machine learning methods for intelligent
experimentation}

In small-animal Neuroscience, most often statistical processing of neural time series is
performed offline;
i.e., experimental data is collected, saved to files, which are later
statistically processed, with no runtime constraints. Most often all
experimental data is processes at the same time; i.e., batch processing.

A new online statistical processing approach is now emerging in small-animal Neuroscience,
where data is processes while it is being collected, and at the speed of data
generation~\citep{vermaniEtAl24}.

Online methods are well suited for NaLoDuCo experimentation. In experiments
extending for weeks to months animals learn and adapt, their motivation and
fatigue may fluctuate, and experimental conditions (e.g., lighting) may change.
Offline batch processing algorithms cannot model this type of changing data.
They assume stationary data whose statistical properties do not change across
time. Differently, most online processing algorithms are robust to
these changes.
%
Also, NaLoDuCo experimentation is well suited for online methods, as the
long-duration of these experiments provide a large amount of data to accurately
fit expressive online methods.

We will \textbf{optimize methods developed for Aim~1 so that they can operate
in real time}, and focus on the following two applications of these online
methods (Figure~\ref{fig:aims}, right box).

\subsubsection*{Intelligent neuromodulation}

Brain activity can be modulated optically, chemically and
electrically~\citep{}.
%
Most commonly these modulations are done at fixed experimental times, or based on
simple behavioral or neural observations.
%
We will guide optogenetic manipulations based on inferences from advanced
machine learning methods.

For example, a scientists may hypothesize that a peak in a neural latent
variable, inferred from a prefrontal cortex population, signals the moment when
mice decide to begin a foraging bout.  To test this, she estimates latent
variables from prefrontal cortex activity online, and forecasts when this peak
will occur. She then optogenetically inactivates the neural population at the
forecasted time.  Because the inactivations prevented the mouse from initiating
a foraging bout, her hypothesis is supported.

\subsubsection*{Intelligent experimental data storage}

As the duration of NaLoDuCo experiments becomes longer, and the volume of the
behavioral and neural recordings becomes larger, it will be unfeasible to
store all raw data. We will be forced to intelligently decide, in real time,
subsets of data to discard. Real-time machine learning methods can guide the
decision of what subset of data to discard, as exemplified below.

If we are recording videos from a mouse foraging in a large arena
with ten high-resolution cameras, it would save considerable storage if at any
time we only save videos from cameras capturing the mouse at that time.  This
could be done by tracking the position of the mouse in real time with
probabilistic machine learning methods. Then, when the confidence of the
tracking is high, we would only save videos of cameras capturing the mouse at
the tracked position, but when the confidence is low, we would save all videos.

\section{Approach}

\subsection{Offline machine learning}

We have collected unprecedented NaLoDuCo datasets at the SWC. However, these
very large datasets are of not much use without methods for visual exploration
and data analysis. The next section describes methods we will disseminate for
data analysis, Section~\ref{sec:visualExploration} presents those for
visualisation, Section~\ref{sec:relatedResearchOfflineAnalysis} discusses
related research, and Section~\ref{sec:outputOfflineAnalysis} mentions outputs
from this aim.

\subsubsection{Analysis methods to disseminate}

We will disseminate advanced statistical methods to analyze recordings from NaLoDuCo
foraging experiments performed at the SWC, where mice forage freely in large
arenas, 24 hours a day and seven days a week, for weeks to months, while their
behavioral and neural activity is recorded with high resolution.

We will create a variety of new methods or adapt existing ones to aid the
exploration of NaLoDuCo recordings at the behavioral and neural levels. These
methods should be robust to process non-stationary data and run efficiently on
distributed computing system (see below).

The first step in the analysis of NaLoDuCo foraging behavioral data is
\textbf{tracking multiple body parts} in mice. For this we will use
\textbf{deep learning} methods, as in
\citep{https://pubmed.ncbi.nlm.nih.gov/30127430/}.
%
Next, we will use the previous tracking outputs to \textbf{infer mice
kinematics} with \textbf{linear dynamical models}, as in
\citep{https://github.com/joacorapela/lds}.
%
We will combine the tracking outputs with the kinematics inferences to
\textbf{infer behavioral states} with \textbf{hidden Markov models}, as in
\citep{https://pubmed.ncbi.nlm.nih.gov/26687221/}.
%
Further, we will \textbf{related kinematics and behavioral states to the
probability of foraging events}, like leaving a patch, with \textbf{generalized
linear models}, as in \citep{}, and \textbf{artificial neural networks}, as in \citep{}.
%
The final step of the behavioral analysis will be to \textbf{infer mice policy
from behavioral measures} with \textbf{inverse reinforcement learning}, as in
\cite{https://arxiv.org/abs/2311.13870v2}.

The characterization of neural data will begin with the \textbf{estimation of latent
variables models}, to reduced the dimensionality of multielectrode recordings of
hundreds or even thousands of neurons to a small number of latent variables,
using \textbf{latent variable models}, with linear~\citep{dunckerAndSahanai18}
and nonlinear~\citep{pandarinathEtAl} latent dynamics..
%
We will use the estimated latent variables as inputs to
\textbf{infer neural states}, using \textbf{HMMs}, as in~\citep{}.
%
Next, we will \textbf{decode mice position} from hippocampal recordings, and
\textbf{study
replay} during long-duration \textbf{foraging}, with \textbf{point process
decoders}, as in \citep{ppDecoder}.

\subsubsection{Challenges}

Extracting meaning from long-duration and continual recordings opens
challenges and opportunities that we will address and exploit in this project,
as we describe in this and the next sections.

\subsubsection*{Non-stationarities}

Conventional offline methods used to characterize neural time series assume
that the statistical characteristics of the modeled data do not change with
time (i.e., that the probability of the data is time invariant --
stationarity). This assumption may be valid for shorter experiments. However,
for long-duration experiments, where animals learn and adapt, where their
motivation fluctuates, and their activity is modulated by circadian, utradiem
and peridiem rhythms, the stationarity assumption may not hold.

The field of adaptive signal processing~\citep{haykin02} develops algorithms to
characterize non-stationary systems. There is no unique solution to optimally
process any non-stationary signal. Instead, adaptations to specific algorithms
have been developed to improve their performance in non-stationary
environments.

For example, the recursive least-squares algorithm \citep[][Chapter
9]{haykin02} is an adaptation of the ordinary least square algorithm to perform
linear regression with non-stationary data.
%
For non-linear regression using artificial neural networks, a very large number
of strategies have been developed to address data non-stationarity. To mention
a few, continual learning has introduced algorithms like  Elastic Weight
Consolidation~\citep[EWC][]{} and Learning Without Forgetting~\citep[LwF][]{}
to allow models to adapt to changes over time without catastrophic forgetting.
Also from this subfield is the Experience Replay (ER) algorithm that stores
past data samples in a buffer and replays them alongside new data during
training. A different type of strategy is used by ensemble methods~\citep{},
which combine multiple models trained on different time windows to capture
evolving data patterns.

Algorithms for state-space models, like the Kalman filter, perform well in some
simpler non-stationary environments producing Gaussian data with varying mean and
covariance.
%
For more complex non-stationarities one can use switching state-pace models,
like the switching linear dynamical system~\cite{} or the switching Hidden
Markov model~\cite{}.

\subsubsection*{Long processing times for very large datasets}

Neural and behavioral data analysis is most effective when computations can be
performed quickly, ideally in real time. Very slow computations discourage data
analysis, and hurts scientific discovery. The large dataset sizes generated by
NaLoDuCo experimentation are an important challenge for fast data analysis.

To overcome this limitation, we will leverage distributed computing, a paradigm
in which tasks and data are divided across multiple computers. Instead of
relying on a single powerful machine, distributed computing accelerates
processing by executing multiple parts of a computation in parallel.

\begin{comment}
For distributed computing to deliver substantial speed improvements,
computations must be decomposable into independent parallel tasks. While not
all algorithms naturally support such decomposition, distributed computing
remains valuable even for non-parallelizable algorithms. For instance, it
enables efficient hyperparameter optimization, where multiple algorithm
configurations can be tested in parallel, significantly reducing overall
runtime.
\end{comment}

We will develop parallel implementations of the of core machine learning
algorithms for behavioral and neural data analysis (Section~\ref{sec:coreMLAlgorithms}).
These implementations will use Apache Spark\footnote{https://spark.apache.org/}
to parallelise pre-processing and feature extraction, and
Ray\footnote{https://docs.ray.io/} to parallelise machine learning and deep
learning functionality.

\subsubsection{Opportunities}

\paragraph{More expressive models}
%
Our long-duration recordings, spanning weeks to months and generating hundreds
of terabytes per experiment, will be transformative for neuroscience, much like
the advent of large-scale datasets in computer vision.  Just as the creation of
MNIST—and later, ImageNet—enabled the training of deeper neural networks,
leading to unprecedented performance breakthroughs, our massive,
high-resolution neural and behavioral datasets will allow the estimation of far
more expressive models than previously possible.
%
For instance, large NaLoDuCo datasets will allo to estimate latent variable
models with highly nonlinear and expressive models of observation given latent
variables using recognition parametrised models~\citep{walkerEtAl23}.
%
By capturing neural dynamics over extended timescales, we may uncover novel
insights into learning, memory, and long-term neural adaptations that remain
inaccessible with conventional short-duration studies.

\paragraph{Study very slow behavioral and neural rhythmic patterns}
%
Continuously monitoring detailed behavioral and neural activity over weeks to
months enables the study of slow rhythmic processes that extend beyond
traditional circadian (~24-hour) rhythms, including ultradian (hours),
infradian (days to weeks), and even multi-month cycles. These long-duration
fluctuations influence learning, memory consolidation, motivation, and
cognitive function, yet they remain largely unexplored in controlled
experiments. By capturing these dynamics, we can gain new insights into neural
plasticity, attention, and mood regulation, as well as the progression of
neurological disorders like Parkinson’s disease and depression, which exhibit
slow symptom fluctuations.

\paragraph{New neuromodulation opportunities}
%
In traditional short-duration experiments, the effects of neuromodulation are
tested immediately. In contrast, our long-duration experiments will enable
repeated neuromodulation over extended periods and allow us to assess its
impact over much longer timescales.
%
For instance, in a mouse model of Alzheimer's disease, we could apply
optogenetic stimulation to the hippocampus for one hour per day over the course
of a month and assess its impact on memory retention and synaptic plasticity in
the following weeks. This approach could reveal whether intermittent
neuromodulation promotes long-term neural circuit stability and delays
cognitive decline.

\subsubsection{Related research}
\label{sec:relatedResearchOfflineAnalysis}

\paragraph{Neural data analysis methods from the Gatsby Unit}
%
The Gatsby Unit has developed world-class neural data analysis methods for
%
inferring latent variables using Gaussian
processes~\citep{yuEtAl09,dunckerAndSahani18,ruttenEtAl20,yuEtAl24}, or variants
of linear dynamical systems~\citep{buesinEtAl12,mackeEtAl15}, or recognition
parameterised models~\citep{walkerEtAl23},
%
for separating contributions of different factors to spiking activity using
tensor decompositions~\citep{soulatEtAl21},
%
and for understanding the effects of neural perturbations~\citep{oSheaEtAl22},
just to mention a few.

\paragraph{Distributed computing for small animal Neuroscience}
%
\citet{freemanEtAl14} introduced a
package\footnote{https://github.com/thunder-project/thunder} for analysing
two-photon imaging records on distributed computing platforms.  This has
been a pioneering development. However, it used short duration recordings and
it implemented simple data analysis methods.

\paragraph{Continuous epilepsy monitoring}
%
Continuous epilepsy monitoring is a critical tool for diagnosing,
understanding, and managing epilepsy.
%
One major advancement in this field is the use of implantable devices, such as
the NeuroPace Responsive Neurostimulation (RNS) system, which continuously
records for extended periods of time (i.e., years) electrocorticographic brain
activity, and delivers electrical stimulation in response to detected seizure
precursors.
%
This  technology has lead to substantial improvement in the treatment of
epilepsy~\citep{rao21}. Yet it has two major limitations, first, it is
invasive, and second, it can only save a few hours of continuous brain activity
for later analysis, limiting its ability for understanding long-duration brain
dynamics.

These limitations are ameliorated by recent technologies for sub-scalp
ultra-long EEG recording monitoring~\citep{duunHenriksenEtAl20}, which record
EEG signals with electrodes implanted under the scalp and over the skull. This
technology is less invasive and, importantly, streams EEG measurements to the
cloud, enabling the characterization of long-duration brain dynamics, with
simultaneous behavioral measurements recorded by other devices.

These devices have significantly improved seizure
control for patients with drug-resistant epilepsy by enabling closed-loop
neuromodulation. Additionally, recent developments in subscalp EEG technology
offer a less invasive alternative to intracranial monitoring while still
providing high-quality long-term recordings, improving patient comfort and
accessibility.

Beyond clinical applications, continuous epilepsy monitoring has deepened our
understanding of epileptic networks and brain dynamics. Studies have revealed
that seizure activity is often modulated by circadian and ultradian rhythms,
with certain times of day showing increased seizure susceptibility. Advances in
machine learning and big-data analysis have further enhanced our ability to
analyze long-duration recordings, leading to more accurate seizure prediction
and classification. As technology continues to evolve, continuous epilepsy
monitoring is expected to play an increasingly central role in both clinical
and research settings, offering new insights into the mechanisms of epilepsy
and improving patient outcomes.

\subsubsection{Outputs}
\label{sec:outputOfflineAnalysis}

Software repository containing implementations of machine learning algorithms
relevant to NaLoDuCo experimentation, adapted to work with non-stationary data,
and optimized to run on distributed computing environments (e.g., public clouds
or institutional high-performance-computing clusters).

\subsection{Visual Exploration}
\label{sec:visualExploration}

\subsubsection{Outputs}

Visualisations for continuous behavioral and neural recording

Visualisations for epoched behavioral and neural recording

Visualisations for model outputs

Indexing system

\subsection{Spike Sorting}

\subsubsection{Outputs}

Repository with implementations and benchmarking of offline spike sorting algorithms for long-duration recordings

Repository with implementations and benchmarking of online spike sorting algorithms

\subsection{Dissemination}
\label{sec:dissemination}

\subsubsection{Outputs}

- web application for the visualisation and analysis of SWC foraging NaLoDuCo recordings in AWS
- documentation on how to build arenas and use the AEON platform and software
- documentation on how to use the online machine learning software

\subsection{Online Machine Learning}

\subsubsection{Outputs}

- Bonsai packages implementing real-time ML functionality for experimetal control
- Documentation of these packages

\subsection{Software and Infrastructure}
% Python, Kubernetes, Apache Spark, Ray, Bonsai, Bonsai.ML

\end{document}
