\subsubsection{Offline Analysis Methods}
\label{sec:offlineAnalysisMethods}

\textbf{Modern neuroscience lacks robust methods to characterize long-duration
and continual time series}, especially in settings where the statistical
properties of the data evolve over time. This limitation present a
methodological gap that must be addressed in order to unlock the scientific
potential of NaLoDuCo experiments.

To bridge this gap, we will develop and disseminate a software library
containing new implementations of existing machine learning methods
specifically tailored to: (1) operate effectively under \textbf{non-stationary}
conditions, and (2) scale to \textbf{very long time series}.

\subsubsection*{Initial List of Methods to Include in the Library}
\label{sec:initialListOfMethods}

We will initially populate this library with new implementations of methods
already in use at GCNU, SWC, and AIND to analyze neural and behavioral time
series in NaLoDuCo foraging and olfactory learning experiments in mice. These
methods span multiple domainsâ€”kinematics, neural dynamics, behavioral state
segmentation, forecasting, and joint modeling. They are related to each other
in the following use case.

\vspace{1em}
\noindent\textbf{Behavioral Analysis:}
The first step in behavioral analysis involves multi-body-part tracking. For
this, we will use \textbf{deep learning-based pose estimation} methods such as
\href{https://github.com/talmolab/sleap}{SLEAP}, which allow tracking of
multiple unmarked mice.

Next, we will infer continuous kinematic variables from these pose estimates
using \textbf{linear dynamical systems (LDS)}, including variants based on
particle filters. These features will be used to infer discrete behavioral
states with \textbf{Hidden Markov Models (HMMs)}, as implemented in tools such
as \href{https://dattalab.github.io/moseq2-website/index.html}{MoSeq}.

We will relate behavioral kinematics and inferred states to foraging-related
outcomes (e.g., patch-leaving decisions) using both \textbf{generalized linear
models (GLMs)} and \textbf{deep neural networks}.
%
To infer behavioral policies,
we will apply \textbf{inverse reinforcement learning} methods such as
\href{https://github.com/haozhu10015/hiql}{HIQL}.

NaLoDuCo recordings enable reliable forecasting over much longer time horizons
than is possible with conventional, short-duration datasets.
%
Leveraging this unique property, we will use methods for long-horizon
behavioral forecasting as \textbf{recurrent neural networks (RNNs)} and
\textbf{transformer architectures}.

\vspace{1em}
\noindent\textbf{Neural Data Analysis:}
Analysis of high-density electrophysiology will begin with \textbf{latent
variable modeling} to reduce the dimensionality of multi-electrode recordings.
We will use models with both linear and nonlinear dynamics, including
\href{https://github.com/joacorapela/svGPFA}{svGPFA} (a Gaussian Process latent
dynamical model) and \href{https://snel.ai/resources/lfads/}{LFADS} (a deep
generative model based on RNNs).

The latent trajectories will be used as inputs to infer discrete neural states
via \textbf{HMMs}, using libraries such as
\href{https://github.com/lindermanlab/ssm}{SSM}. For long-duration forecasting
of neural activity, we will again employ \textbf{RNNs} and
\textbf{transformers}.

We will also perform spatial decoding from hippocampal spikes using
\textbf{point-process decoders}, enabling the study of long-term replay during
naturalistic foraging, as implemented in
\href{https://github.com/Eden-Kramer-Lab/replay_trajectory_classification}{replay\_trajectory\_classification}.

\vspace{1em}
\noindent\textbf{Joint Neural-Behavioral Modeling:}
To better understand the relationships between neural and behavioral processes,
we will develop models that extract \textbf{shared latent variables} from both
domains. This includes
\href{https://github.com/gatsby-sahani/rpm-aistats-2023}{Recognition-Parametrized
Models (RPM)}, a method developed at the GCNU allowing inferences of latent
variables related to observations in highly nonlinear ways,
and \href{https://cebra.ai/}{CEBRA}, a recent contrastive learning
approach for multimodal representation learning.

