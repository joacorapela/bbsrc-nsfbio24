

\textbf{Modern neuroscience lacks robust methods to characterize long-duration
and continual time series}, especially in settings where the statistical
properties of the data evolve over time. This limitation present a
methodological gap that must be addressed in order to unlock the scientific
potential of NaLoDuCo experiments.

To bridge this gap, we will develop and disseminate a software library
containing new implementations of existing machine learning methods
specifically tailored to: (1) operate effectively under \textbf{non-stationary}
conditions, and (2) scale to \textbf{very long time series}.

\subsubsubsection{Initial List of Methods to Include in the Library}
\label{sec:initialListOfMethods}

We will initially populate this library with new implementations of methods
already in use at the GCNU, SWC, and AIND to analyze neural and behavioral time
series from NaLoDuCo foraging and olfactory learning experiments in mice. These
methods span multiple domains—kinematics, neural dynamics, behavioral state
segmentation, forecasting, and joint modeling—and are designed to work together
within an integrated analysis pipeline.

\vspace{1em}
\noindent\textbf{Behavioral Analysis:}  
The first step in behavioral analysis involves multi-body-part tracking. For
this, we will use \textbf{deep learning-based pose estimation} methods such as
\href{https://github.com/talmolab/sleap}{SLEAP}, which enable accurate and
efficient tracking of multiple unmarked mice across long recording sessions.

From the tracked poses, we will infer continuous kinematic variables using
\textbf{linear dynamical systems (LDS)}, including particle filter-based
variants to handle uncertainty and measurement noise. These kinematic features
will be used to infer discrete behavioral states with \textbf{Hidden Markov
Models (HMMs)}, as implemented in tools such as
\href{https://dattalab.github.io/moseq2-website/index.html}{MoSeq}.

We will relate these inferred states and kinematic variables to
foraging-related outcomes—such as patch-leaving decisions—using both
\textbf{generalized linear models (GLMs)} and \textbf{deep neural networks}.
These models will allow us to capture both interpretable and high-capacity
representations of behavioral decision-making processes.

To recover the latent strategies guiding animal behavior, we will apply
\textbf{inverse reinforcement learning} methods such as
\href{https://github.com/haozhu10015/hiql}{HIQL}, which estimate the underlying
reward functions and policies based on observed actions.

NaLoDuCo recordings uniquely support behavioral forecasting over extended
horizons—ranging from hours to days—far beyond what is feasible in conventional
short-duration experiments. To capitalize on this, we will apply
long-horizon forecasting models using \textbf{recurrent neural networks (RNNs)}
and \textbf{transformer architectures}, which are well-suited to modeling
long-range temporal dependencies.

\vspace{1em}
\noindent\textbf{Neural Data Analysis:}  
Analysis of high-density electrophysiology will begin with \textbf{latent
variable modeling} to reduce the dimensionality of population neural
recordings. We will use both linear and nonlinear latent dynamics models,
including \href{https://github.com/joacorapela/svGPFA}{svGPFA}, which uses
Gaussian processes, and \href{https://snel.ai/resources/lfads/}{LFADS}, a deep
generative model based on recurrent neural networks.

The resulting low-dimensional trajectories will be used to infer discrete
neural states via \textbf{HMMs}, using methods such as
\href{https://github.com/lindermanlab/ssm}{SSM}. For neural activity
forecasting across long durations, we will again employ \textbf{RNNs} and
\textbf{transformers}, which can model complex temporal structure in spiking
activity.

We will also decode the animal’s position from hippocampal spike trains using
\textbf{point-process decoders}, enabling the analysis of spatial coding and
replay phenomena during naturalistic foraging behavior. We will build on
existing implementations such as
\href{https://github.com/Eden-Kramer-Lab/replay_trajectory_classification}{replay\_trajectory\_classification}.

\vspace{1em}
\noindent\textbf{Joint Neural-Behavioral Modeling:}  
To understand the interactions between neural dynamics and behavior, we will
use models that extract \textbf{shared latent representations} from both
domains. These models will help reveal how cognitive and behavioral states are
jointly encoded in neural activity.

We will adapt
\href{https://github.com/gatsby-sahani/rpm-aistats-2023}{Recognition-Parametrized
Models (RPM)}, a Bayesian approach developed at the GCNU, which infers latent
variables that explain multiple observation streams through highly nonlinear
relationships. We will also use \href{https://cebra.ai/}{CEBRA}, a
state-of-the-art contrastive learning framework designed for multimodal
representation learning, to discover temporally and semantically aligned
neural-behavioral structure.

\subsubsubsection{Non-stationarity}

Many conventional methods for analyzing neural and behavioral time series
assume that the underlying data-generating processes are stationary—that is,
their statistical properties remain constant over time. While this assumption
may be acceptable in short-duration experiments, it breaks down in
long-duration and continual recordings. In such settings, animals
learn and adapt, their internal states and motivations fluctuate, and their
behavior and physiology are influenced by biological rhythms such as circadian,
ultradian, and infradian cycles. These changes induce non-stationarity in the
data, making models that assume stationarity progressively less reliable or
even obsolete.

To address this challenge, we will adapt and develop methods that are
explicitly designed to operate in non-stationary environments. Our approach
draws on techniques from multiple domains, including adaptive signal
processing, machine learning, and Bayesian inference.

\paragraph{Adaptive Signal Processing.}

The field of adaptive signal processing has produced robust methods for
modeling linear systems with time-varying dynamics~\citep{haykin02}.
%
The recursive least-squares (RLS) algorithm, for example, is a well-known
adaptation of the ordinary least squares algorithm that continuously updates
model parameters to perform linear regression under non-stationary conditions.
%
We will use RLS to study time-varying relations between
behavioral states, as inferred by hidden Markov models, and foraging visit
durations.

\paragraph{Continual Learning.}

The field of continual learning develops adaptive methods for
artificial neural networks.  In classic continual learning, a model learns a
sequence of discrete, well-defined tasks.  But in NaLoDuCo experimentation, as
in many real-world settings there are not specific task boundaries. So methods
that do not require task boundaries are needed. They are studied by the
subfield of task-free continual learning and include online
regularization (which constrain the update of relevant weights), experience
replay (which maintain a small, representative buffer of past samples) and
ensemble methods (which combine the predictions of multiple individual models
with, for example, different learning rates).
%
We will use these techniques, for example, to train pose tracking models on
month-long continuous recordings.

\paragraph{Adaptive State-Space Models.}

In state-space modeling, the Kalman filter provides a principled way to handle
non-stationary Gaussian processes with drifting mean and covariance. More
flexible approaches are needed when data exhibit abrupt regime shifts or
complex latent dynamics. Switching state-space models, such as Switching Linear
Dynamical Systems (SLDS) and Switching Hidden Markov Models (sHMMs), model
discrete changes in underlying system dynamics. For nonlinear, non-Gaussian
signals, particle filters approximate the posterior distribution through
sequential sampling. Bayesian online learning techniques offer a general
framework for continually updating model parameters as new data arrive.
%
Using these techniques we will build models that robustly infer kinematics
over months.

\begin{comment}

\paragraph{Concept Drift in Machine Learning.}

In the machine learning literature, non-stationarity is often studied under the
framework of \emph{concept drift}~\citep{conceptdriftReview}, which refers to
shifts in the joint distribution of inputs and outputs over time.
%
Drift may be sudden, gradual, or cyclical (e.g., re-emergence of behavioral
patterns linked to circadian modulation).
%
Techniques for handling concept drift fall into several broad categories: (1)
detection methods, which monitor for significant distributional changes; (2)
adaptation methods, which adjust models incrementally using sliding windows,
online learning, or ensemble updates; and (3) forgetting mechanisms, which
allow models to "forget" outdated information while retaining relevant past
knowledge.
%
We will use techniques from concept drift for models that do not fall in the
previous categories (i.e.; they are not linear models, artificial neural
network models or state-space models).
%
For instance, we will use these techniques to build \href{RPM}s to estimate
joint behavioral and neural latents across months.

In summary, robust modeling of NaLoDuCo datasets demands tools that adapt
continuously to changing data distributions. Our offline analysis framework
will incorporate both well-established adaptive algorithms and cutting-edge
methods from continual learning and concept drift research to address this
fundamental challenge.

\end{comment}

\paragraph{Concept Drift in Machine Learning.}

In the machine learning literature, non-stationarity is often framed under the
concept of \emph{concept drift}~\citep{conceptdriftReview}, which refers to
changes in the joint distribution of inputs and outputs over time. Such drift
can take various forms—sudden, gradual, or cyclical (e.g., re-emergence of
behavioral patterns linked to circadian or ultradian rhythms).

Techniques for handling concept drift generally fall into three categories: (1)
\emph{detection methods}, which monitor for significant changes in data
distribution; (2) \emph{adaptation methods}, which incrementally update models
using strategies such as sliding windows, online learning, or ensemble-based
approaches; and (3) \emph{forgetting mechanisms}, which allow models to discard
outdated information while retaining relevant past knowledge.

We will apply techniques from the concept drift literature to models that fall
outside our primary categories of focus (e.g., linear models, artificial neural
networks, and state-space models). In particular, we will explore their use in
building
\href{https://github.com/gatsby-sahani/rpm-aistats-2023}{Recognition-Parametrized
Models (RPMs)} to estimate joint behavioral and neural latent variables over
timescales of weeks to months.

In summary, robust analysis of NaLoDuCo datasets requires models that
continuously adapt to evolving data distributions. Our offline analysis
framework will integrate both established adaptive algorithms and cutting-edge
methods from continual learning and concept drift to meet this challenge.

\subsubsubsection{Computational efficiency}

Neural and behavioral data analysis is most effective when computations are
performed quickly, ideally in real time. Slow computations discourage data
exploration and hinder scientific discovery. The large dataset sizes generated by
NaLoDuCo experimentation pose a significant challenge for fast data analysis.

To overcome this limitation, we will combine distributed and GPU computing.
%
Distributed computing is a paradigm
in which tasks and data are divided across multiple computers. Instead of
relying on a single powerful machine, distributed computing accelerates
processing by executing multiple parts of a computation in parallel.
%
GPU computing is a parallel computing approach that uses Graphics Processing
Units (GPUs) to accelerate computational tasks. Unlike traditional Central
Processing Units (CPUs), which execute a few complex operations sequentially,
GPUs consist of thousands of smaller cores optimized for executing many
operations simultaneously.

Distributed and GPU computing address different bottlenecks in large-scale
computation. GPUs are highly efficient at parallelizing operations within a
single machine. They excel at matrix operations and batch processing. However,
GPUs are limited by memory and cannot scale indefinitely when dealing with huge
datasets that exceed the GPU memory.
%
Distributed computing allows to split workload across multiple machines,
overcoming memory and computational limitations. It is particularly useful for
scaling to massive datasets (e.g., long-term time series recordings).

For distributed computing to deliver substantial speed improvements,
computations must be decomposable into independent parallel tasks. Due to their
serial dependencies, time series models are difficult to decomposed in this
manner.

Still, time series models can benefit from distributed computing
infrastructures, as many parts of time series pipelines are parallelizable,
like preprocessing steps (e.g., filtering, feature extraction, normalization)
or parallel model evaluation across hyperparameter sweeps.

In addtion,  when datasets are too large to fit in memory, distributed
computing (e.g., with Ray, Dask, or Spark) can Distribute I/O and
preprocessing, train models in parallel on different subsets (e.g., one model
per animal or time window) and run hyperparameter sweeps or model variants in
parallel.

Furthermore, even with serial dependencies GPU acceleration significantly
speeds up the processing of each item in the time series, specially when large
matrix operation are involved.

% distributed computing for time series models

% parallel version of the Kalman filter

We will develop accelerated implementations of all methods in the library.
These implementations will use \href{https://docs.jax.dev/}{JAX} for model
learning, inference, and numerical computation,
\href{https://spark.apache.org/}{Apache Spark} or
\href{https://www.dask.org/}{Dask} to distribute pre-processing and feature
extraction, and \href{https://docs.ray.io/}{Ray} to distribute machine learning
and deep learning functionality.

Related to this item is the library
\href{Thunder}{https://github.com/thunder-project/thunder}, which accelerate the
analysis of large scale neural data. It was pioneering by introducing the use
of distributed computing in neural data analysis.
%
Our library is different from
\href{Thunder}{https://github.com/thunder-project/thunder} in that, besides
analyzing large scale neural data, it processes continual recordings, and needs
to overcome non-stationarity problems.
%
In addition, it includes methods to characterize behavior, while Thunder
focuses on neural activity.
%
Furthermore, \href{Thunder}{https://github.com/thunder-project/thunder}
implements simpler methods assuming independent and identically distributed
data, while our library contains more sophisticated time series ones.

