\subsubsection{Context}

Conventional systems neuroscience experiments are typically short in duration
and often place significant constraints on subjects behaviours to simplify data
analysis.
%
However, these restrictions may limit our ability to observe critical
aspects of brain function and behaviour that only manifest in more naturalistic
and extended conditions.

At the Sainsbury Wellcome Centre (SWC) and Gatsby Computational Neuroscience
Unit (GCNU) we are pioneering Naturalistic, Long-Duration, and Continual
(NaLoDuCo) foraging experiments in mice that span weeks to months. During these
experiments, we collect high-resolution behavioural and neural recordings in
naturalistic settings.

This novel  approach will enable researchers to explore neural mechanisms
underlying ethological behaviours in naturalistic environments over months, for
the first time.  The experiments will shed new light on a wide range of poorly
understood neural mechanisms, including how the brain structures complex
behavioural sequences as a function of the animal needs, learning and social
dynamics.
%
The data generated from NaLoDuCo experiments represent an entirely new resource
in neuroscience, with the potential to drive breakthroughs and discoveries that
are beyond the reach of traditional experiments.

While experiments in neuroscience that are naturalistic, long-duration, or
continuous have been conducted in the past (e.g.,
[\href{https://pubmed.ncbi.nlm.nih.gov/37656619/}{1}]), to the best of our
knowledge, we are the first to integrate all three of these features in a
single experimental paradigm.
%
Experiments of this type have been advocated by experts in the field years ago
([\href{https://pubmed.ncbi.nlm.nih.gov/31600508/}{2}], p.19), yet they have
not been implemented so far.

The central goal of the Allen Institute for Neural Dynamics (AIND), our US
collaborator, is to understand how the brain works at the level of individual
neurons.
%
Central to its mission is the development of neuro-technologies to acquire and
distribute massive ammounts of neural data.
%
They are also investigating foraging behavior, but using head-fixed mice.

% Since the project started in 2021, our UK business partner, NeuroGEARS Ltd.\
% has been contracted by the SWC to lead the implementation of the NaLoDuCo
% experimental framework. It also provides services to the AIND.

The extremely large datasets--on the order of hundreds of terabytes--gathered
from experiments spanning weeks to months pose significant challenges in data
acquisition, management, distribution, visualisation, and analysis.
%
Together, the GCNU, SWC and AIND will address these challenges, co-develop this
new type of experimentation, share expertise and build software infrastructure
to help scientists around the world perform NaLoDuCo experiments.

\subsubsection{Focus areas}

Developing platform technologies for:

\begin{description}

    \item[Experimental Control, Data Acquisition \& Management] Controlling
        sophisticated experiments and efficiently gathering and organising
        massive datasets over extended periods.

    \item[Data Sharing] Providing global access to large-scale datasets.

    \item[Data Visualisation] Building web-based visualisation of very large
        behavioural and neural data.

    \item[Data Analysis] Characterising behavioural and neural recordings with
        advanced machine learning methods.

\end{description}

\subsubsection{Specific benefits from our collaboration}

The foraging experiments at the AIND are different from those at the SWC. They
do not probe freely moving and naturalistic behaviour, but are able to perform
electrophysiological recordings more densely than those at the SWC.
%
These experimental approaches to foraging are complementary and this
collaboration will greatly benefit both of them.

Currently, both GCNU and AIND are independently developing methods to address
the previous focus areas. We will join forces to co-develop these methods and
our foraging research programs, leveraging our combined expertise for greater
impact.
